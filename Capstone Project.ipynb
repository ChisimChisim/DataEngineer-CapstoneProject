{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Engineering Capstone Project\n",
    "### Data Lake with Spark\n",
    "\n",
    "#### Project Summary\n",
    "Data Lake project with Spark for Imigration analystic team.\n",
    "\n",
    "The project follows the follow steps:\n",
    "* Step 1: Scope the Project and Gather Data\n",
    "* Step 2: Explore and Assess the Data\n",
    "* Step 3: Define the Data Model\n",
    "* Step 4: Run ETL to Model the Data\n",
    "* Step 5: Complete Project Write Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do all imports and installs here\n",
    "import pandas as pd\n",
    "import configparser\n",
    "import os\n",
    "from pyspark.sql.functions import when\n",
    "from pyspark.sql.functions import col, split, udf, date_add, monotonically_increasing_id\n",
    "from pyspark.sql.types import DoubleType, IntegerType\n",
    "import datetime\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "### Step 1: Scope the Project and Gather Data\n",
    "\n",
    "#### Scope \n",
    "Immigration analytics team for the U.S. goverment wants to investigate the immigrant's age, total number by state of stay, country of immigrant citizen, and etc.. Thay also want to track immigtants who arrival and departure records don't match, and want to know state where they stay after they arrived and the demographic of the state.  To allow the analytics team to find insight in them, Data enginners will load data, process the data into analytics tables using Spark, and load them back into S3. We want to analyze each month, so we use only data of 04/2016 in this project.\n",
    "#### Describe and Gather Data  \n",
    "1. I94 Immigration Data: This data comes from the US National Tourism and Trade Office. A data dictionary is included in the workspace. This is where the data comes from. \n",
    "2. U.S. City Demographic Data: This data comes from OpenSoft.\n",
    "3. Airport Code Table: This is a simple table of airport codes and corresponding cities. It comes from DataHub.\n",
    "4. Country code data: This is simple table of I-94 immigrant's nationality. This is from a data dictionary of I94 Immigration Data.\n",
    "5. State code data: This is simple table of US state code. This is from a data dictionary of I94 Immigration Data.\n",
    "6. City code data: This is simple table of US city code. This is from a data dictionary of I94 Immigration Data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data here\n",
    "## Get the i94 immigration data\n",
    "fname = '../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat'\n",
    "df_i94 = pd.read_sas(fname, 'sas7bdat', encoding=\"ISO-8859-1\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Get the city demographic data\n",
    "df_demog = pd.read_csv(\"us-cities-demographics.csv\", sep=\";\")\n",
    "\n",
    "## Get Airport code data\n",
    "df_airport = pd.read_csv(\"airport-codes_csv.csv\")\n",
    "\n",
    "## Get Country Code data\n",
    "df_country = pd.read_csv(\"country-code.csv\", sep=\";\")\n",
    "\n",
    "## Get State Code data\n",
    "df_state = pd.read_csv(\"state-code.csv\", sep=\";\")\n",
    "\n",
    "## Get City Code data\n",
    "df_city = pd.read_csv(\"city-code.csv\", sep=\";\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cicid</th>\n",
       "      <th>i94yr</th>\n",
       "      <th>i94mon</th>\n",
       "      <th>i94cit</th>\n",
       "      <th>i94res</th>\n",
       "      <th>i94port</th>\n",
       "      <th>arrdate</th>\n",
       "      <th>i94mode</th>\n",
       "      <th>i94addr</th>\n",
       "      <th>depdate</th>\n",
       "      <th>...</th>\n",
       "      <th>entdepu</th>\n",
       "      <th>matflag</th>\n",
       "      <th>biryear</th>\n",
       "      <th>dtaddto</th>\n",
       "      <th>gender</th>\n",
       "      <th>insnum</th>\n",
       "      <th>airline</th>\n",
       "      <th>admnum</th>\n",
       "      <th>fltno</th>\n",
       "      <th>visatype</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>692.0</td>\n",
       "      <td>XXX</td>\n",
       "      <td>20573.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>U</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1979.0</td>\n",
       "      <td>10282016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.897628e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>254.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>ATL</td>\n",
       "      <td>20551.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>Y</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1991.0</td>\n",
       "      <td>D/S</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.736796e+09</td>\n",
       "      <td>00296</td>\n",
       "      <td>F1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>WAS</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MI</td>\n",
       "      <td>20691.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>M</td>\n",
       "      <td>NaN</td>\n",
       "      <td>OS</td>\n",
       "      <td>6.666432e+08</td>\n",
       "      <td>93</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>16.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>1988.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17.0</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>NYC</td>\n",
       "      <td>20545.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>MA</td>\n",
       "      <td>20567.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>M</td>\n",
       "      <td>2012.0</td>\n",
       "      <td>09302016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>AA</td>\n",
       "      <td>9.246846e+10</td>\n",
       "      <td>00199</td>\n",
       "      <td>B2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   cicid   i94yr  i94mon  i94cit  i94res i94port  arrdate  i94mode i94addr  \\\n",
       "0    6.0  2016.0     4.0   692.0   692.0     XXX  20573.0      NaN     NaN   \n",
       "1    7.0  2016.0     4.0   254.0   276.0     ATL  20551.0      1.0      AL   \n",
       "2   15.0  2016.0     4.0   101.0   101.0     WAS  20545.0      1.0      MI   \n",
       "3   16.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "4   17.0  2016.0     4.0   101.0   101.0     NYC  20545.0      1.0      MA   \n",
       "\n",
       "   depdate   ...     entdepu  matflag  biryear   dtaddto gender insnum  \\\n",
       "0      NaN   ...           U      NaN   1979.0  10282016    NaN    NaN   \n",
       "1      NaN   ...           Y      NaN   1991.0       D/S      M    NaN   \n",
       "2  20691.0   ...         NaN        M   1961.0  09302016      M    NaN   \n",
       "3  20567.0   ...         NaN        M   1988.0  09302016    NaN    NaN   \n",
       "4  20567.0   ...         NaN        M   2012.0  09302016    NaN    NaN   \n",
       "\n",
       "  airline        admnum  fltno visatype  \n",
       "0     NaN  1.897628e+09    NaN       B2  \n",
       "1     NaN  3.736796e+09  00296       F1  \n",
       "2      OS  6.666432e+08     93       B2  \n",
       "3      AA  9.246846e+10  00199       B2  \n",
       "4      AA  9.246846e+10  00199       B2  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_i94.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>State</th>\n",
       "      <th>Median Age</th>\n",
       "      <th>Male Population</th>\n",
       "      <th>Female Population</th>\n",
       "      <th>Total Population</th>\n",
       "      <th>Number of Veterans</th>\n",
       "      <th>Foreign-born</th>\n",
       "      <th>Average Household Size</th>\n",
       "      <th>State Code</th>\n",
       "      <th>Race</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Silver Spring</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>33.8</td>\n",
       "      <td>40601.0</td>\n",
       "      <td>41862.0</td>\n",
       "      <td>82463</td>\n",
       "      <td>1562.0</td>\n",
       "      <td>30908.0</td>\n",
       "      <td>2.60</td>\n",
       "      <td>MD</td>\n",
       "      <td>Hispanic or Latino</td>\n",
       "      <td>25924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Quincy</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>41.0</td>\n",
       "      <td>44129.0</td>\n",
       "      <td>49500.0</td>\n",
       "      <td>93629</td>\n",
       "      <td>4147.0</td>\n",
       "      <td>32935.0</td>\n",
       "      <td>2.39</td>\n",
       "      <td>MA</td>\n",
       "      <td>White</td>\n",
       "      <td>58723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hoover</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>38.5</td>\n",
       "      <td>38040.0</td>\n",
       "      <td>46799.0</td>\n",
       "      <td>84839</td>\n",
       "      <td>4819.0</td>\n",
       "      <td>8229.0</td>\n",
       "      <td>2.58</td>\n",
       "      <td>AL</td>\n",
       "      <td>Asian</td>\n",
       "      <td>4759</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Rancho Cucamonga</td>\n",
       "      <td>California</td>\n",
       "      <td>34.5</td>\n",
       "      <td>88127.0</td>\n",
       "      <td>87105.0</td>\n",
       "      <td>175232</td>\n",
       "      <td>5821.0</td>\n",
       "      <td>33878.0</td>\n",
       "      <td>3.18</td>\n",
       "      <td>CA</td>\n",
       "      <td>Black or African-American</td>\n",
       "      <td>24437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Newark</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>34.6</td>\n",
       "      <td>138040.0</td>\n",
       "      <td>143873.0</td>\n",
       "      <td>281913</td>\n",
       "      <td>5829.0</td>\n",
       "      <td>86253.0</td>\n",
       "      <td>2.73</td>\n",
       "      <td>NJ</td>\n",
       "      <td>White</td>\n",
       "      <td>76402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               City          State  Median Age  Male Population  \\\n",
       "0     Silver Spring       Maryland        33.8          40601.0   \n",
       "1            Quincy  Massachusetts        41.0          44129.0   \n",
       "2            Hoover        Alabama        38.5          38040.0   \n",
       "3  Rancho Cucamonga     California        34.5          88127.0   \n",
       "4            Newark     New Jersey        34.6         138040.0   \n",
       "\n",
       "   Female Population  Total Population  Number of Veterans  Foreign-born  \\\n",
       "0            41862.0             82463              1562.0       30908.0   \n",
       "1            49500.0             93629              4147.0       32935.0   \n",
       "2            46799.0             84839              4819.0        8229.0   \n",
       "3            87105.0            175232              5821.0       33878.0   \n",
       "4           143873.0            281913              5829.0       86253.0   \n",
       "\n",
       "   Average Household Size State Code                       Race  Count  \n",
       "0                    2.60         MD         Hispanic or Latino  25924  \n",
       "1                    2.39         MA                      White  58723  \n",
       "2                    2.58         AL                      Asian   4759  \n",
       "3                    3.18         CA  Black or African-American  24437  \n",
       "4                    2.73         NJ                      White  76402  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_demog.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ident</th>\n",
       "      <th>type</th>\n",
       "      <th>name</th>\n",
       "      <th>elevation_ft</th>\n",
       "      <th>continent</th>\n",
       "      <th>iso_country</th>\n",
       "      <th>iso_region</th>\n",
       "      <th>municipality</th>\n",
       "      <th>gps_code</th>\n",
       "      <th>iata_code</th>\n",
       "      <th>local_code</th>\n",
       "      <th>coordinates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00A</td>\n",
       "      <td>heliport</td>\n",
       "      <td>Total Rf Heliport</td>\n",
       "      <td>11.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-PA</td>\n",
       "      <td>Bensalem</td>\n",
       "      <td>00A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00A</td>\n",
       "      <td>-74.93360137939453, 40.07080078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00AA</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Aero B Ranch Airport</td>\n",
       "      <td>3435.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-KS</td>\n",
       "      <td>Leoti</td>\n",
       "      <td>00AA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AA</td>\n",
       "      <td>-101.473911, 38.704022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00AK</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Lowell Field</td>\n",
       "      <td>450.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AK</td>\n",
       "      <td>Anchor Point</td>\n",
       "      <td>00AK</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AK</td>\n",
       "      <td>-151.695999146, 59.94919968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00AL</td>\n",
       "      <td>small_airport</td>\n",
       "      <td>Epps Airpark</td>\n",
       "      <td>820.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AL</td>\n",
       "      <td>Harvest</td>\n",
       "      <td>00AL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>00AL</td>\n",
       "      <td>-86.77030181884766, 34.86479949951172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00AR</td>\n",
       "      <td>closed</td>\n",
       "      <td>Newport Hospital &amp; Clinic Heliport</td>\n",
       "      <td>237.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>US</td>\n",
       "      <td>US-AR</td>\n",
       "      <td>Newport</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-91.254898, 35.6087</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ident           type                                name  elevation_ft  \\\n",
       "0   00A       heliport                   Total Rf Heliport          11.0   \n",
       "1  00AA  small_airport                Aero B Ranch Airport        3435.0   \n",
       "2  00AK  small_airport                        Lowell Field         450.0   \n",
       "3  00AL  small_airport                        Epps Airpark         820.0   \n",
       "4  00AR         closed  Newport Hospital & Clinic Heliport         237.0   \n",
       "\n",
       "  continent iso_country iso_region  municipality gps_code iata_code  \\\n",
       "0       NaN          US      US-PA      Bensalem      00A       NaN   \n",
       "1       NaN          US      US-KS         Leoti     00AA       NaN   \n",
       "2       NaN          US      US-AK  Anchor Point     00AK       NaN   \n",
       "3       NaN          US      US-AL       Harvest     00AL       NaN   \n",
       "4       NaN          US      US-AR       Newport      NaN       NaN   \n",
       "\n",
       "  local_code                            coordinates  \n",
       "0        00A     -74.93360137939453, 40.07080078125  \n",
       "1       00AA                 -101.473911, 38.704022  \n",
       "2       00AK            -151.695999146, 59.94919968  \n",
       "3       00AL  -86.77030181884766, 34.86479949951172  \n",
       "4        NaN                    -91.254898, 35.6087  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_airport.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>country</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>582</td>\n",
       "      <td>MEXICO Air Sea, and Not Reported (I-94, no lan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>236</td>\n",
       "      <td>AFGHANISTAN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>ALBANIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>316</td>\n",
       "      <td>ALGERIA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102</td>\n",
       "      <td>ANDORRA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   code                                            country\n",
       "0   582  MEXICO Air Sea, and Not Reported (I-94, no lan...\n",
       "1   236                                        AFGHANISTAN\n",
       "2   101                                            ALBANIA\n",
       "3   316                                            ALGERIA\n",
       "4   102                                            ANDORRA"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_country.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AL</td>\n",
       "      <td>ALABAMA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AK</td>\n",
       "      <td>ALASKA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AZ</td>\n",
       "      <td>ARIZONA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AR</td>\n",
       "      <td>ARKANSAS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CA</td>\n",
       "      <td>CALIFORNIA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  code        name\n",
       "0   AL     ALABAMA\n",
       "1   AK      ALASKA\n",
       "2   AZ     ARIZONA\n",
       "3   AR    ARKANSAS\n",
       "4   CA  CALIFORNIA"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_state.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>code</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALC</td>\n",
       "      <td>ALCAN</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANC</td>\n",
       "      <td>ANCHORAGE</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BAR</td>\n",
       "      <td>BAKERAAF-BAKERISLAND</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DAC</td>\n",
       "      <td>DALTONSCACHE</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PIZ</td>\n",
       "      <td>DEWSTATIONPTLAYDEW</td>\n",
       "      <td>AK</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  code                  city state\n",
       "0  ALC                 ALCAN    AK\n",
       "1  ANC             ANCHORAGE    AK\n",
       "2  BAR  BAKERAAF-BAKERISLAND    AK\n",
       "3  DAC          DALTONSCACHE    AK\n",
       "4  PIZ    DEWSTATIONPTLAYDEW    AK"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_city.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = configparser.ConfigParser()\n",
    "config.read('dl.cfg')\n",
    "\n",
    "os.environ[\"AWS_ACCESS_KEY_ID\"]=config['AWS'][\"AWS_ACCESS_KEY_ID\"]\n",
    "os.environ[\"AWS_SECRET_ACCESS_KEY\"]=config['AWS'][\"AWS_SECRET_ACCESS_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "config(\"spark.jars.packages\",\"org.apache.hadoop:hadoop-aws:2.8.5\")\\\n",
    ".enableHiveSupport().getOrCreate()\n",
    "df_i94_spark =spark.read.format('com.github.saurfang.sas.spark').load('../../data/18-83510-I94-Data-2016/i94_apr16_sub.sas7bdat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.\\\n",
    "config(\"spark.jars.packages\",\"saurfang:spark-sas7bdat:2.0.0-s_2.11\").\\\n",
    "config(\"spark.jars.packages\",\"org.apache.hadoop:hadoop-aws:2.8.5\")\\\n",
    ".enableHiveSupport().getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_demog_spark = spark.read.csv(\"us-cities-demographics.csv\", sep=\";\", inferSchema=True, header=True)\n",
    "df_airport_spark = spark.read.csv(\"airport-codes_csv.csv\", inferSchema=True, header=True)\n",
    "df_country_spark = spark.read.csv(\"country-code.csv\", sep=\";\", inferSchema=True, header=True)\n",
    "df_state_spark = spark.read.csv(\"state-code.csv\", sep=\";\", inferSchema=True, header=True)\n",
    "df_city_spark = spark.read.csv(\"city-code.csv\", sep=\";\", inferSchema=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write to parquet\n",
    "#df_i94_spark.write.parquet(\"sas_data\")\n",
    "df_i94_spark=spark.read.parquet(\"sas_data\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Explore and Assess the Data\n",
    "#### Explore the Data & Cleaning Steps\n",
    "Identify data quality issues, like missing values, duplicate data, etc.\n",
    "Regarding i-94 Immigrants data, \"i94port\" should be only city in US. So if the state of port is not in US, the date should not be include in this project. Because i-94 immigrants arrive in US. \n",
    "\n",
    "<ul><strong>i94 Immigration data</strong>\n",
    "    <li><strong>cicid:</strong> Records with duplicate data and missing value should be deleted.</li>\n",
    "    <li><strong>port:</strong> Port should be only in us.</li>\n",
    "    <li><strong>i94addr:</strong> All missing values should be \"99\". </li>\n",
    "    <li><strong>matflag:</strong> All missing values should be \"X\". </li>\n",
    "    <li><strong>gender:</strong> All missing values should be \"X\". </li>\n",
    "</ul>    \n",
    "<ul><strong>city demographic data</strong>\n",
    "    <li><strong>city&state:</strong> Records with missing value should be deleted.</li>\n",
    "    <li><strong>city&state&race:</strong> Records with duplicate data should be deleted.</li>  \n",
    "</ul>    \n",
    "<ul><strong>airport code data</strong>\n",
    "    <li><strong>ident:</strong> Records with duplicate data and missing value should be deleted.</li>\n",
    "</ul>  \n",
    "<ul><strong>country code data</strong>\n",
    "    <li><strong>code:</strong> Records with duplicate data and missing value should be deleted.</li>\n",
    "</ul>  \n",
    "<ul><strong>state code data AND city code data</strong>\n",
    "    <li>There are non-US cities. The port or entry means first port where immigrants arrived in US. So do inner-join state code data and city code data, and then keep only US cities. </li> \n",
    "    <li><strong>code:</strong> Records with duplicate data and missing value should be deleted.</li>\n",
    "</ul> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performing cleaning tasks here\n",
    "df_demog_spark = df_demog_spark.filter(df_demog_spark.City.isNotNull())\\\n",
    "                            .filter(df_demog_spark.State.isNotNull())\\\n",
    "                            .dropDuplicates(subset=['City', 'State', 'Race'])\n",
    "\n",
    "df_airport_spark = df_airport_spark.filter(df_airport_spark.ident.isNotNull())\\\n",
    "                                .dropDuplicates(subset=['ident'])\n",
    "\n",
    "df_country_spark = df_country_spark.filter(df_country_spark.countryid.isNotNull())\\\n",
    "                                .dropDuplicates(subset=['countryid']) \n",
    "\n",
    "df_state_spark = df_state_spark.filter(df_state_spark.stateid.isNotNull())\\\n",
    "                                .dropDuplicates(subset=['stateid']) \n",
    "\n",
    "df_citystate_spark = df_city_spark.join(df_state_spark, df_city_spark.state == df_state_spark.stateid)\\\n",
    "                             .select(\"cityid\", \"city\", \"stateid\", \"name\")\\\n",
    "                             .filter(df_city_spark.cityid.isNotNull())\\\n",
    "                                .dropDuplicates(subset=['cityid']) \n",
    "\n",
    "fill_X = udf(lambda x: \"X\" if x is None else x) \n",
    "df_i94_spark = df_i94_spark.join(df_citystate_spark, df_i94_spark.i94port == df_citystate_spark.cityid)\\\n",
    "                        .filter(df_i94_spark.cicid.isNotNull())\\\n",
    "                        .dropDuplicates(subset=['cicid'])\\\n",
    "                        .withColumn(\"i94addr\", when(df_i94_spark.i94addr==\"\", \"99\").otherwise(df_i94_spark.i94addr))\\\n",
    "                        .withColumn(\"matflag\", fill_X(df_i94_spark.matflag))\\\n",
    "                        .withColumn(\"gender\", fill_X(df_i94_spark.gender))\n",
    "                        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the Data Model\n",
    "#### 3.1 Conceptual Data Model\n",
    "The below 5 models are defined. <font color=\"red\"> Please see the file \"Schema_model.xlsx\" in the Workspace.</font>\n",
    "<ol>\n",
    "<b>*Fact model</b>\n",
    "<li>immigrants table - </li>\n",
    "<b>*Dimention models</b>\n",
    "<li>demographics table</li>\n",
    "<li>airports table</li>\n",
    "<li>countries table</li>\n",
    "<li>ports table</li>    \n",
    "</ol>\n",
    "\n",
    "#### 3.2 Mapping Out Data Pipelines\n",
    "List the steps necessary to pipeline the data into the chosen data model\n",
    "* Step 1: Insert data from df_citystate_spark to ports table\n",
    "* Step 2: Insert data from df_countries_spark to countries table\n",
    "* Step 3: Select only airports in US. Separate \"coordinates\" to \"latitude\" and \"longitude\" in df_airport_spark, and insert data to airports table with collect data type.\n",
    "* Step 4: Create demographics table with population each races by city&state. Demographics table is created with collect data type.\n",
    "* Step 5: Change SAS date numeric to timestamp, change transportation mode code to text, and visa type code to text, and then insert data from df_i94_spark to immigrants table with collect data type.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Run Pipelines to Model the Data \n",
    "#### 4.1 Create the data model\n",
    "Build the data pipelines to create the data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create cities table\n",
    "ports_table = df_citystate_spark.selectExpr(\"cityid as portid\", \"city\", \"stateid\", \"name as state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create countries tabke\n",
    "countries_table = df_country_spark.selectExpr(\"countryid\", \"country\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create airports table\n",
    "airports_table = df_airport_spark.filter(df_airport_spark.iso_country==\"US\")\\\n",
    "                                 .withColumn(\"stateid\", split(df_airport_spark.iso_region, \"-\")[1])\\\n",
    "                                 .withColumn(\"latitude\", split(df_airport_spark.coordinates, \",\")[0]\\\n",
    "                                 .cast(DoubleType()))\\\n",
    "                                 .withColumn(\"longitude\", split(df_airport_spark.coordinates, \",\")[1]\\\n",
    "                                 .cast(DoubleType()))\\\n",
    "                                 .selectExpr(\"ident as airportid\", \"type\", \"name as airportname\",\\\n",
    "                                   \"elevation_ft\", \"iso_country\", \"stateid\", \"municipality\", \"latitude\", \"longitude\")\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create demographics table\n",
    "\n",
    "hispanic = df_demog_spark.select(\"City\", \"State\", \"Median Age\", \"Male Population\", \\\n",
    "        \"Female Population\", \"Total Population\", \"Foreign-born\", \"Average Household Size\", \\\n",
    "        \"State Code\", \"Count\").where(df_demog_spark.Race==\"Hispanic or Latino\")\\\n",
    "         .withColumnRenamed(\"City\", \"city\")\\\n",
    "         .withColumnRenamed(\"State\", \"state\")\\\n",
    "         .withColumnRenamed(\"Median Age\", \"median_age\")\\\n",
    "         .withColumnRenamed(\"Male Population\", \"male_population\")\\\n",
    "         .withColumnRenamed(\"Female Population\", \"female_population\")\\\n",
    "         .withColumnRenamed(\"Total Population\", \"total_population\")\\\n",
    "         .withColumnRenamed(\"Foreign-born\", \"foreign_born\")\\\n",
    "         .withColumnRenamed(\"Average Household Size\", \"ave_household\")\\\n",
    "         .withColumnRenamed(\"State Code\", \"stateid\")\\\n",
    "         .withColumnRenamed(\"Count\", \"hispanic_latino\")\n",
    "\n",
    "white = df_demog_spark.selectExpr(\"City as city\", \"State as state\", \"Count as white\").where(df_demog_spark.Race==\"White\")\n",
    "asian = df_demog_spark.selectExpr(\"City as city\", \"State as state\", \"Count as asian\").where(df_demog_spark.Race==\"Asian\")\n",
    "black = df_demog_spark.selectExpr(\"City as city\", \"State as state\", \"Count as black_africanAmerican\").where(df_demog_spark.Race==\"Black or African-American\")\n",
    "native = df_demog_spark.selectExpr(\"City as city\", \"State as state\", \"Count as americanIndian_alaskaNative\").where(df_demog_spark.Race==\"American Indian and Alaska Native\")\n",
    "\n",
    "demographics_table = hispanic.join(white, (hispanic.city==white.city) & (hispanic.state==white.state))\\\n",
    "                             .join(asian, (hispanic.city==asian.city) & (hispanic.state==asian.state))\\\n",
    "                             .join(black, (hispanic.city==black.city) & (hispanic.state==black.state))\\\n",
    "                             .join(native, (hispanic.city==native.city) & (hispanic.state==native.state))\\\n",
    "                             .withColumn(\"demographicsid\", monotonically_increasing_id())\\\n",
    "                             .select(\"demographicsid\", hispanic.city, hispanic.state, \"median_age\", \"male_population\", \"female_population\", \\\n",
    "                                    \"total_population\", \"foreign_born\", \"ave_household\", \"stateid\", \\\n",
    "                                     \"hispanic_latino\", \"white\", \"asian\", \"black_africanAmerican\", \"americanIndian_alaskaNative\")\\\n",
    "                             .withColumn(\"median_age\", hispanic.median_age.cast(IntegerType()))\\\n",
    "                             .withColumn(\"male_population\", hispanic.male_population.cast(IntegerType()))\\\n",
    "                             .withColumn(\"female_population\", hispanic.female_population.cast(IntegerType()))\\\n",
    "                             .withColumn(\"total_population\", hispanic.total_population.cast(IntegerType()))\\\n",
    "                             .withColumn(\"foreign_born\", hispanic.foreign_born.cast(IntegerType()))\\\n",
    "                             .withColumn(\"ave_household\", hispanic.ave_household.cast(DoubleType()))\\\n",
    "                             .withColumn(\"hispanic_latino\", hispanic.hispanic_latino.cast(IntegerType()))\\\n",
    "                             .withColumn(\"white\", white.white.cast(IntegerType()))\\\n",
    "                             .withColumn(\"asian\", asian.asian.cast(IntegerType()))\\\n",
    "                             .withColumn(\"black_africanAmerican\", black.black_africanAmerican.cast(IntegerType()))\\\n",
    "                             .withColumn(\"americanIndian_alaskaNative\", native.americanIndian_alaskaNative.cast(IntegerType()))\\\n",
    "                             \n",
    "\n",
    "                   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create immigrants table\n",
    "from pyspark.sql.functions import col, split, udf, date_add, current_date\n",
    "get_date = udf(lambda x: datetime.datetime(1,1,1).strftime('%Y-%m-%d %H:%M:%S') if x is None else\\\n",
    "               (datetime.datetime(1960, 1, 1) + datetime.timedelta(seconds=int(x*24*60*60)))\\\n",
    "               .strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "immigrants_table = df_i94_spark.withColumn(\"cicid\", df_i94_spark.cicid.cast(IntegerType()))\\\n",
    "                               .withColumn(\"i94yr\", df_i94_spark.i94yr.cast(IntegerType()))\\\n",
    "                               .withColumn(\"i94mon\", df_i94_spark.i94mon.cast(IntegerType()))\\\n",
    "                               .withColumn(\"i94cit\", df_i94_spark.i94cit.cast(IntegerType()))\\\n",
    "                               .withColumn(\"i94res\", df_i94_spark.i94res.cast(IntegerType()))\\\n",
    "                               .withColumn(\"arrival_date\", get_date(df_i94_spark.arrdate))\\\n",
    "                               .withColumn(\"mode\", df_i94_spark.i94mode.cast(IntegerType()))\\\n",
    "                               .withColumn(\"mode_text\", when(df_i94_spark.i94mode==1, \"Air\")\\\n",
    "                                           .when(df_i94_spark.i94mode==2, \"Sea\")\\\n",
    "                                           .when(df_i94_spark.i94mode==3, \"Land\")\\\n",
    "                                           .otherwise(\"Not Reported\"))\\\n",
    "                               .withColumn(\"departure_date\", get_date(df_i94_spark.depdate))\\\n",
    "                               .withColumn(\"i94bir\", df_i94_spark.i94bir.cast(IntegerType()))\\\n",
    "                               .withColumn(\"visa\", df_i94_spark.i94visa.cast(IntegerType()))\\\n",
    "                               .withColumn(\"visa_text\", when(df_i94_spark.i94visa==1, \"Business\")\\\n",
    "                                           .when(df_i94_spark.i94visa==2, \"Pleasure\")\\\n",
    "                                           .when(df_i94_spark.i94visa==3, \"Student\")\\\n",
    "                                           .otherwise(\"Not Reported\"))\\\n",
    "                               .withColumn(\"bityear\", df_i94_spark.biryear.cast(IntegerType()))\\\n",
    "                               .withColumn(\"admnum\", df_i94_spark.admnum.cast(IntegerType()))\\\n",
    "                               .selectExpr(\"cicid as immigrandid\", \"i94yr as year\", \"i94mon as month\", \\\n",
    "                   \"i94cit as country_citizen\", \"i94res as county_residence\", \"i94port as portid\", \"arrival_date\", \\\n",
    "                   \"mode\", \"mode_text\", \"i94addr as stateid\", \"departure_date\", \"i94bir as age\", \"visa\", \"visa_text\", \"matflag\", \\\n",
    "                   \"biryear\", \"gender\", \"airline\", \"admnum\", \"fltno\", \"visatype\")\\\n",
    "                               \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2 Data Quality Checks\n",
    "Explain the data quality checks you'll perform to ensure the pipeline ran as expected. These could include:\n",
    " * Integrity constraints on the relational database (e.g., unique key, data type, etc.)\n",
    " * Unit tests for the scripts to ensure they are doing the right thing\n",
    " * Source/Count checks to ensure completeness\n",
    " \n",
    "Run Quality Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- demographicsid: long (nullable = false)\n",
      " |-- city: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      " |-- median_age: integer (nullable = true)\n",
      " |-- male_population: integer (nullable = true)\n",
      " |-- female_population: integer (nullable = true)\n",
      " |-- total_population: integer (nullable = true)\n",
      " |-- foreign_born: integer (nullable = true)\n",
      " |-- ave_household: double (nullable = true)\n",
      " |-- stateid: string (nullable = true)\n",
      " |-- hispanic_latino: integer (nullable = true)\n",
      " |-- white: integer (nullable = true)\n",
      " |-- asian: integer (nullable = true)\n",
      " |-- black_africanAmerican: integer (nullable = true)\n",
      " |-- americanIndian_alaskaNative: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Check DataType of demographics table\n",
    "demographics_table.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- airportid: string (nullable = true)\n",
      " |-- type: string (nullable = true)\n",
      " |-- airportname: string (nullable = true)\n",
      " |-- elevation_ft: integer (nullable = true)\n",
      " |-- iso_country: string (nullable = true)\n",
      " |-- stateid: string (nullable = true)\n",
      " |-- municipality: string (nullable = true)\n",
      " |-- latitude: double (nullable = true)\n",
      " |-- longitude: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Check DataType of airports_table\n",
    "airports_table.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- countryid: integer (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Check DataType of countries_table\n",
    "countries_table.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- portid: string (nullable = true)\n",
      " |-- city: string (nullable = true)\n",
      " |-- stateid: string (nullable = true)\n",
      " |-- state: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Check DataType of ports_table\n",
    "ports_table.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- immigrandid: integer (nullable = true)\n",
      " |-- year: integer (nullable = true)\n",
      " |-- month: integer (nullable = true)\n",
      " |-- country_citizen: integer (nullable = true)\n",
      " |-- county_residence: integer (nullable = true)\n",
      " |-- portid: string (nullable = true)\n",
      " |-- arrival_date: string (nullable = true)\n",
      " |-- mode: integer (nullable = true)\n",
      " |-- mode_text: string (nullable = false)\n",
      " |-- stateid: string (nullable = true)\n",
      " |-- departure_date: string (nullable = true)\n",
      " |-- age: integer (nullable = true)\n",
      " |-- visa: integer (nullable = true)\n",
      " |-- visa_text: string (nullable = false)\n",
      " |-- matflag: string (nullable = true)\n",
      " |-- biryear: double (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- airline: string (nullable = true)\n",
      " |-- admnum: integer (nullable = true)\n",
      " |-- fltno: string (nullable = true)\n",
      " |-- visatype: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Check DataType of immigrants table\n",
    "immigrants_table.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+----------+\n",
      "|stateid|statecount|\n",
      "+-------+----------+\n",
      "|     FL|    593101|\n",
      "|     NY|    529507|\n",
      "|     CA|    451232|\n",
      "|     HI|    165853|\n",
      "|     TX|    129899|\n",
      "+-------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Unit tests for the scripts to ensure they are doing the right thing\n",
    "from pyspark.sql.functions import isnan, count, when, col, desc, udf, col, sort_array, asc, avg\n",
    "## Top 5 Numbe of Immigrants by state of stay\n",
    "sql = immigrants_table.select(\"stateid\")\\\n",
    "                      .groupBy('stateid') \\\n",
    "                      .agg({'stateid':'count'}) \\\n",
    "                      .withColumnRenamed('count(stateid)', 'statecount') \\\n",
    "                      .sort(desc('statecount')) \\\n",
    "                      .show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+-------+------------+\n",
      "|          city|stateid|foreign_born|\n",
      "+--------------+-------+------------+\n",
      "|         Miami|     FL|      260789|\n",
      "|  Jacksonville|     FL|       85650|\n",
      "|Pembroke Pines|     FL|       62210|\n",
      "|         Tampa|     FL|       58795|\n",
      "|     Hollywood|     FL|       55158|\n",
      "+--------------+-------+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Foreign-born population in top 1 state of stay\n",
    "sql = demographics_table.select(\"city\", \"stateid\", \"foreign_born\").where(demographics_table.stateid==\"FL\")\\\n",
    ".sort(desc('foreign_born')).show(5)\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----+-----+---------------+----------------+------+-------------------+----+---------+-------+----------------+---+----+---------+-------+-------+------+-------+----------+-----+--------+\n",
      "|immigrandid|year|month|country_citizen|county_residence|portid|       arrival_date|mode|mode_text|stateid|  departure_date|age|visa|visa_text|matflag|biryear|gender|airline|    admnum|fltno|visatype|\n",
      "+-----------+----+-----+---------------+----------------+------+-------------------+----+---------+-------+----------------+---+----+---------+-------+-------+------+-------+----------+-----+--------+\n",
      "|      11757|2016|    4|            111|             111|   CHI|2016-04-01 00:00:00|   1|      Air|     IL|1-01-01 00:00:00| 63|   2| Pleasure|      X| 1953.0|     X|     AF|2147483647|00144|      WT|\n",
      "|      12275|2016|    4|            114|             114|   SPM|2016-04-01 00:00:00|   1|      Air|     CA|1-01-01 00:00:00| 47|   1| Business|      X| 1969.0|     X|     DL|2147483647|00165|      WB|\n",
      "|      13607|2016|    4|            116|             249|   MIA|2016-04-01 00:00:00|   1|      Air|     CA|1-01-01 00:00:00| 54|   1| Business|      X| 1962.0|     M|     AA|2147483647|00087|      WB|\n",
      "|      27240|2016|    4|            133|             264|   NYC|2016-04-01 00:00:00|   1|      Air|     US|1-01-01 00:00:00| 26|   3|  Student|      X| 1990.0|     M|     PS|2147483647|00231|      F1|\n",
      "|      29559|2016|    4|            135|             135|   DAL|2016-04-01 00:00:00|   1|      Air|     TX|1-01-01 00:00:00| 33|   2| Pleasure|      X| 1983.0|     X|     BA|2147483647|00193|      WT|\n",
      "|      36818|2016|    4|            135|             135|   ORL|2016-04-01 00:00:00|   1|      Air|     FL|1-01-01 00:00:00| 32|   2| Pleasure|      X| 1984.0|     M|     VS|2147483647|00027|      WT|\n",
      "|      47157|2016|    4|            148|             112|   NEW|2016-04-01 00:00:00|   1|      Air|     NY|1-01-01 00:00:00| 25|   2| Pleasure|      X| 1991.0|     M|     LH|2147483647|00408|      WT|\n",
      "|      52546|2016|    4|            167|             167|   NYC|2016-04-01 00:00:00|   1|      Air|     NJ|1-01-01 00:00:00| 71|   2| Pleasure|      X| 1945.0|     F|     TK|2147483647|00001|      B2|\n",
      "|      63867|2016|    4|            213|             213|   HOU|2016-04-01 00:00:00|   1|      Air|     LA|1-01-01 00:00:00| 61|   2| Pleasure|      X| 1955.0|     F|     EK|2147483647|00211|      B2|\n",
      "|      95756|2016|    4|            528|             528|   DEN|2016-04-01 00:00:00|   1|      Air|     NY|1-01-01 00:00:00| 72|   2| Pleasure|      X| 1944.0|     M|     AV|2147483647|00574|      B2|\n",
      "|     214045|2016|    4|            692|             692|   NYC|2016-04-01 00:00:00|   1|      Air|     NY|1-01-01 00:00:00| 19|   2| Pleasure|      X| 1997.0|     F|     AV|2147483647|00244|      B2|\n",
      "|     230912|2016|    4|            111|             111|   SAJ|2016-04-02 00:00:00|   1|      Air|     PR|1-01-01 00:00:00| 53|   2| Pleasure|      X| 1963.0|     M|    GUY|2147483647|00103|      WT|\n",
      "|     239923|2016|    4|            126|             126|   DET|2016-04-02 00:00:00|   1|      Air|   null|1-01-01 00:00:00| 37|   2| Pleasure|      X| 1979.0|     F|     YX|2147483647|04400|      WT|\n",
      "|     256618|2016|    4|            135|             135|   ORL|2016-04-02 00:00:00|   1|      Air|     FL|1-01-01 00:00:00| 40|   2| Pleasure|      X| 1976.0|     M|     BA|2147483647|02037|      WT|\n",
      "|     262869|2016|    4|            135|             135|   PHO|2016-04-02 00:00:00|   1|      Air|     FL|1-01-01 00:00:00| 47|   2| Pleasure|      X| 1969.0|     F|     BA|2147483647|02167|      WT|\n",
      "|     280428|2016|    4|            209|             209|   CHI|2016-04-02 00:00:00|   1|      Air|     IL|1-01-01 00:00:00|  4|   1| Business|      X| 2012.0|     M|     JL|2147483647|00010|      E2|\n",
      "|     280485|2016|    4|            209|             209|   SEA|2016-04-02 00:00:00|   1|      Air|     WA|1-01-01 00:00:00| 19|   3|  Student|      X| 1997.0|     F|     NH|2147483647|00178|      F1|\n",
      "|     280754|2016|    4|            209|             209|   HOU|2016-04-02 00:00:00|   1|      Air|     TX|1-01-01 00:00:00| 12|   1| Business|      X| 2004.0|     M|     NH|2147483647|00174|      E2|\n",
      "|     280895|2016|    4|            209|             209|   LOS|2016-04-02 00:00:00|   1|      Air|     CA|1-01-01 00:00:00| 20|   3|  Student|      X| 1996.0|     F|     JL|2147483647|00062|      F1|\n",
      "|     281622|2016|    4|            213|             213|   NYC|2016-04-02 00:00:00|   1|      Air|     NJ|1-01-01 00:00:00| 65|   2| Pleasure|      X| 1951.0|     X|     EK|2147483647|00203|      B2|\n",
      "+-----------+----+-----+---------------+----------------+------+-------------------+----+---------+-------+----------------+---+----+---------+-------+-------+------+-------+----------+-----+--------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#immigtants who arrival and departure records don't match\n",
    "immigrants_table.filter(immigrants_table.matflag==\"X\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3 Data dictionary \n",
    "Create a data dictionary for your data model. For each field, provide a brief description of what the data is and where it came from. \n",
    "<p><strong>Please see file \"Schema_model.xlsx\" </strong></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 5: Complete Project Write Up\n",
    "* Clearly state the rationale for the choice of tools and technologies for the project.\n",
    "The immigrants dataset is analystic data rather than structured data. So Data lake is better than Data Warehouse. Apache Spark process ETL pipeline for the data lake and HDSF is used for data strage in EMR. Because Apache Spark allow us in this project fast and in-memory data processing and data straged on HDFS is accessed by BI app or Advanced Analystic App.\n",
    "\n",
    "* Propose how often the data should be updated and why.\n",
    " <p>As data set of only 04/2016 is used in this project, the immigrants data should be updated once a month. On the other hand, other data sets don't change frequently so they should be updated once a year.  </p>\n",
    " \n",
    " \n",
    "* Write a description of how you would approach the problem differently under the following scenarios:\n",
    " * The data was increased by 100x.\n",
    " <p>First of all, all data should be ingested from S3. Second, we can add nodes and increase process capacity in EMR. But If we want to save cost even if the processing speed is low, we can change them to spark+S3 (not HDFS).    </p>\n",
    " * The data populates a dashboard that must be updated on a daily basis by 7am every day.\n",
    " <p>The data lake process should be scheduled by Airflow </p>\n",
    " * The database needed to be accessed by 100+ people.\n",
    " <p>We can add nodes and increase process capacity. And also "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
